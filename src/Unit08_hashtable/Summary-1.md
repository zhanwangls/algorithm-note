### 散列表

#### 特点

散列表用的是数组支持按照下标随机访问数据的特性，所以散列表是数组的一种扩展，由数组演化而来。

我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化为数组下标，从对应的数组下标位置取数据。所以散列函数在散列表中起着非常关键的作用。

#### 散列函数设计的基本要求:

1. 散列函数计算的散列值是一个非负整数
2. 如果key1=key2，那hash(key1)=hash(key2)
3. 如果key1≠key2，那hash(key1)≠hash(key2)

其中第3点，要求看起来合情合理，但是真实情况下，要想找到一个不同key对应的散列值都不一样的散列函数，几乎是不可能的。即使像MD5,SHA,CRC等业界著名的哈希算法，也无法完全避免散列冲突。而且因为数组的存储空间有限，也会加大散列冲突的概率。

所以我们几乎无法找到一个完美的无冲突的散列函数，即便能找到，付出的时间成本、计算成本也是很大的。针对散列冲突问题，我们需要通过其他途径来解决。

#### 解决散列冲突常用的两种方法：

1. 开放寻址法
   核心思想是，如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。

   如何重新探测新的位置？

   a. 线性探测

   插入：当我们往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。

   查找：过程类似插入。通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素。如果相等，则说明就是我们要找的元素；否则就顺序往后依次查找。如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。

   删除：不能单纯地把要删除的元素设置为空。因为在查找的时候，一旦我们找到一个空闲位置，就可以认定散列表中不存在这个数据。如果这个空闲位置是我们后来删除的，就会导致原来的查找算法失效。本来存在的数据，会被认定为不存在。可以将删除的元素，特殊标记为 deleted。当线性探测查找的时候，遇到标记为 deleted 的空间，并不是停下来，而是继续往下探测。

   缺点：当散列表中插入的数据越来越多时，散列冲突发生的可能性就会越来越大，空闲位置会越来越少，线性探测的时间就会越来越久。

   b. 二次探测

   跟线性探测很像，线性探测每次探测的步长是 1，而二次探测探测的步长就变成了原来的“二次方”，也就是说，它探测的下标序列就是 hash(key)+0，hash(key)+1^2，hash(key)+2^2……

   c. 双重散列

   不仅使用一个散列函数，而是使用一组散列函数 hash1(key)，hash2(key)，hash3(key)……先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置。

   装载因子：

   不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，一般情况下，我们会尽可能保证散列表中有一定比例的空闲槽位。我们用装载因子（load factor）来表示空位的多少。

   散列表的装载因子=填入表中的元素个数/散列表的长度。

   装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。

2. 链表法

   是更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多。

   在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。

   插入：只需要通过散列函数计算出对应的散列槽位，将其插入到对应链表中即可，所以插入的时间复杂度是 O(1)。

   查找、删除：通过散列函数计算出对应的槽，然后遍历链表查找或者删除。时间复杂度O(k),k表示链表长度，对于散列均匀的函数，k=n/m,n表示散列中数据的个数，m表示散列表中“槽”的个数。

#### 查询时间复杂度：

与散列函数、装载因子、散列冲突有关，不能简单说成O(1)。

#### 散列表碰撞攻击:

有些恶意的攻击者，有可能通过精心构造的数据，使得所有的数据经过散列函数之后，都散列到同一个槽里。如果我们使用的是基于链表的冲突解决方法，那这个时候，散列表就会退化为链表，查询的时间复杂度就从 O(1) 急剧退化为 O(n)。这样就有可能因为查询操作消耗大量 CPU 或者线程资源，导致系统无法响应其他请求，从而达到拒绝服务攻击（DoS）的目的。这也就是散列表碰撞攻击的基本原理。

#### 实现工业级的散列表
1. 设计散列函数

   设计不能太复杂，否则本身的计算时间间接影响了散列表的性能。

   散列函数生成的值尽可能随机并且均匀分布。这样可以最小化冲突，即使冲突，每个槽的数据量也会比较平均。

   考虑实际因素，关键字的长度、特点等等。

2. 装载因子设定

   装载因子阈值的设置要权衡时间、空间复杂度。如果内存空间不紧张，对执行效率要求很高，可以降低负载因子的阈值；相反，如果内存空间紧张，对执行效率要求又不高，可以增加负载因子的值，甚至可以大于 1。

3. 装载因子过大了怎么办

   可以进行动态扩容，重新申请一个更大的散列表，将数据搬移到这个新散列表中。

   针对散列表的扩容，数据搬移操作要复杂很多。因为散列表的大小变了，数据的存储位置也变了，所以我们需要通过散列函数重新计算每个数据的存储位置。根据摊还分析，时间复杂度为O(1)。

   对于动态散列表，随着数据的删除，散列表中的数据会越来越少，空闲空间会越来越多。如果我们对空间消耗非常敏感，我们可以在装载因子小于某个值之后，启动动态缩容。当然，如果我们更加在意执行效率，能够容忍多消耗一点内存空间，那就可以不用费劲来缩容了。

4. 避免低效扩容

   当装载因子已经到达阈值，需要先进行扩容，再插入数据。这个时候，插入数据就会变得很慢。尽管大部分情况下，插入一个数据的操作都很快，但是，极个别非常慢的插入操作，也会让用户崩溃。这个时候，“一次性”扩容的机制就不合适了。

   我们可以将扩容操作穿插在插入操作的过程中，分批完成。

   当装载因子触达阈值之后，我们只申请新空间，但并不将老的数据搬移到新散列表中。当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，我们都重复上面的过程。经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。

   对于查询操作，为了兼容了新、老散列表中的数据，我们先从新散列表中查找，如果没有找到，再去老的散列表中查找。

   这种实现方式，任何情况下，插入一个数据的时间复杂度都是 O(1)。

5. 如何选择冲突解决方法

   a. 开放寻址法

   优点：

   散列表中的数据都存储在数组中，可以有效地利用 CPU 缓存加快查询速度。

   这种方法实现的散列表，序列化起来比较简单。

   缺点：

   删除数据的时候比较麻烦，需要特殊标记已经删除掉的数据。

   冲突代价更高。

   装载因子的上限不能太大。这也导致这种方法比链表法更浪费内存空间。

   适合：

   数据量比较小、装载因子小。如：ThreadLocalMap

   b. 链表法

   优点：

   对内存的利用率高，因为链表结点可以在需要的时候再创建。

   对大装载因子的容忍度更高，即便装载因子变成 10，也就是链表的长度变长了而已，虽然查找效率有所下降，但是比起顺序查找还是快很多。

   灵活性高，支持更多的优化策略，可以将链表改成其他高效的数据结构，如：红黑树、跳表。

   耗内存，因为要存储指针，但是如果是大对象，指针的这些空间消耗就可以忽略不计了。

   缺点：

   对 CPU 缓存不友好，因为链表中的结点是零散分布在内存中的。

   耗内存，因为要存储指针，但是如果是大对象，指针的这些空间消耗就可以忽略不计了。

   适合：

   大对象、大数据量的散列表。如：LinkedHashMap

#### 分析HashMap

1. 初始大小：16

   这个默认值是可以设置的，如果事先知道大概的数据量有多大，可以通过修改默认初始大小，减少动态扩容的次数，这样会大大提高 HashMap 的性能。

2. 装载因子：0.75

3. 动态扩容：原来2倍大小

4. 散列冲突解决：链表法

   jdk8中，链表长度过长时（8），链表转换为红黑树，利用红黑树可以快速增删改查的特点改善性能。

   红黑树节点少于8，红黑树转换为链表。小数据量时，红黑树要维持平衡，优势不明显。

5. 散列函数：不复杂，追求高效、均匀分布

   ```
   int hash(Object key) {
       int h = key.hashCode()；
       return (h ^ (h >>> 16)) & (capicity -1); //capicity表示散列表的大小
   }
   ```

   